from A_config import DEFAULT_OSR_OPTION, DEFAULT_CPE_FIT_OPTION, PROCESS_MODE_FUNCTIONS,NORM_FACTOR
import pandas as pd
import numpy as np

from A_design_matrix import osr_wk6p_rk6p, osr_wk20p_rk15p, osr_wk20p_rk18p, osr_wk20p_rk19p, osr_wk20p_rk20p
from A_design_matrix import cpe_15para, cpe_18para, cpe_6para, cpe_20para, cpe_k_to_fit
from A_design_matrix import DESIGN_MATRIX_FUNCTIONS
from sklearn.linear_model import Ridge

def kmrc_decorrect(df_raw, df_KMRC):
    x, y, rx, ry = get_coordinates(df_raw)
    
    # [★수정] 좌표 정규화 추가
    x = x / NORM_FACTOR
    y = y / NORM_FACTOR
    rx = rx / NORM_FACTOR
    ry = ry / NORM_FACTOR

    X_dx, X_dy = osr_wk20p_rk20p(x, y, rx, ry)
    mrc_k_odd, mrc_k_even = get_mrc_k_values(df_KMRC)

    if mrc_k_odd is None: # 예외처리 추가
        return pd.DataFrame() # 혹은 에러 처리

    mrc_fit_x = X_dx.dot(mrc_k_odd) * -1
    mrc_fit_y = X_dy.dot(mrc_k_even) * -1
    
    X_reg_demrc = df_raw['X_reg'].values - mrc_fit_x
    Y_reg_demrc = df_raw['Y_reg'].values - mrc_fit_y

    mrc_list = pd.DataFrame({
        'mrc_fit_x': mrc_fit_x,
        'mrc_fit_y': mrc_fit_y,
        'X_reg_demrc': X_reg_demrc,
        'Y_reg_demrc': Y_reg_demrc,
    })

    return mrc_list

def get_coordinates(df):
    die_x = df['DieX'].values
    die_y = df['DieY'].values
    step_pitch_x = df['STEP_PITCH_X'].values
    step_pitch_y = df['STEP_PITCH_Y'].values
    map_shift_x = df['MAP_SHIFT_X'].values
    map_shift_y = df['MAP_SHIFT_Y'].values
    coordinate_x = df['coordinate_X'].values
    coordinate_y = df['coordinate_Y'].values

    x = die_x * step_pitch_x + map_shift_x
    y = die_y * step_pitch_y + map_shift_y
    rx = coordinate_x
    ry = coordinate_y

    return x, y, rx, ry

def get_mrc_k_values(df_KMRC):
    mrc_k_odd = df_KMRC[
        (df_KMRC['K'].isin([
            'W1', 'W3', 'W5', 'W7', 'W9', 'W11', 'W13', 'W15', 'W17', 'W19',
            'R3', 'R5', 'R7', 'R9', 'R11', 'R13', 'R15', 'R17', 'R19'
        ]))
    ]['value'].values.astype(float)
    mrc_k_even = df_KMRC[
        (df_KMRC['K'].isin([
            'W2', 'W4', 'W6', 'W8', 'W10', 'W12', 'W14', 'W16', 'W18', 'W20',
            'R4', 'R6', 'R8', 'R10', 'R12', 'R14', 'R16', 'R18', 'R20'
        ]))
    ]['value'].values.astype(float)

    if len(mrc_k_odd) != 19 or len(mrc_k_even) != 19:
        return None, None
    
    return mrc_k_odd, mrc_k_even

def remove_psm_add_pointmrc(df_raw):
    df_raw['raw_x'] = df_raw['X_reg_demrc'] + df_raw['MRC_X'] 
    df_raw['raw_y'] = df_raw['Y_reg_demrc'] + df_raw['MRC_Y'] 
    return df_raw

def regression(df_raw, osr_option, lot_wf, type_code):
    """
    여러 로트의 데이터를 그룹별로 회귀분석하고 예측 및 잔차를 계산하는 함수.
    osr_option에 따른 디자인 행렬과 회귀 계수 키를 매핑 테이블로 관리하여,
    조건 분기 코드를 단순화했습니다.
    """
    # osr_option에 따른 회귀 계수 키 목록 매핑 테이블
    coeff_keys_mapping = {
        '18para': {
            'dx': ['WK1', 'WK3', 'WK5', 'WK7', 'WK9', 'WK11', 'WK13', 'WK15', 'WK17', 'WK19',
                   'RK3', 'RK5', 'RK7', 'RK9', 'RK11', 'RK15', 'RK17', 'RK19'],
            'dy': ['WK2', 'WK4', 'WK6', 'WK8', 'WK10', 'WK12', 'WK14', 'WK16', 'WK18', 'WK20',
                   'RK4', 'RK6', 'RK8', 'RK10', 'RK12', 'RK14', 'RK16', 'RK18']
        },
        '15para': {
            'dx': ['WK1', 'WK3', 'WK5', 'WK7', 'WK9', 'WK11', 'WK13', 'WK15', 'WK17', 'WK19',
                   'RK3', 'RK5', 'RK7', 'RK11', 'RK19'],
            'dy': ['WK2', 'WK4', 'WK6', 'WK8', 'WK10', 'WK12', 'WK14', 'WK16', 'WK18', 'WK20',
                   'RK4', 'RK6', 'RK8', 'RK10', 'RK12', 'RK14', 'RK16']
        },
        '6para': {
            'dx': ['WK1', 'WK3', 'WK5', 'RK3', 'RK5'],
            'dy': ['WK2', 'WK4', 'WK6', 'RK4', 'RK6']
        },
        '19para': {
            'dx': ['WK1', 'WK3', 'WK5', 'WK7', 'WK9', 'WK11', 'WK13', 'WK15', 'WK17', 'WK19',
                   'RK3', 'RK5', 'RK7', 'RK9', 'RK11', 'RK13', 'RK15', 'RK17', 'RK19'],
            'dy': ['WK2', 'WK4', 'WK6', 'WK8', 'WK10', 'WK12', 'WK14', 'WK16', 'WK18', 'WK20',
                   'RK4', 'RK6', 'RK8', 'RK10', 'RK12', 'RK14', 'RK16', 'RK18']
        }
    }
    
    # 선택된 osr_option에 따른 계수 키 목록을 매핑 테이블에서 가져옴.
    # 만약 osr_option이 매핑 테이블에 없으면 기본값으로 '19para'를 사용합니다.
    coeff_keys = coeff_keys_mapping.get(osr_option, coeff_keys_mapping['19para'])
    dx_coeff_keys = coeff_keys['dx']
    dy_coeff_keys = coeff_keys['dy']
    
    # 디자인 행렬 함수 선택 (기존 매핑 사용)
    dm_func = DESIGN_MATRIX_FUNCTIONS['osr'][osr_option]
    
   
    wkrk_results = []
    
    # 예측값과 잔차를 저장할 컬럼을 미리 생성
    df_raw['pred_x'] = np.nan
    df_raw['pred_y'] = np.nan
    df_raw['residual_x'] = np.nan
    df_raw['residual_y'] = np.nan


    x, y, rx, ry = get_coordinates(df_raw)


    X_dx, X_dy = dm_func(x, y, rx, ry)
    
    # PROCESS_MODE에 따른 Y값 선택 (기본은 'ADI')
    if type_code == 'ADI':
        Y_dx, Y_dy = PROCESS_MODE_FUNCTIONS.get('ADI')(df_raw)
    else:
        Y_dx, Y_dy = PROCESS_MODE_FUNCTIONS.get('OCO')(df_raw)
    
    # 최소자승법으로 회귀 계수 계산
    coeff_dx = np.linalg.lstsq(X_dx, Y_dx, rcond=None)[0]
    coeff_dy = np.linalg.lstsq(X_dy, Y_dy, rcond=None)[0]
    
    # 회귀 계수 저장
    result_coeffs = {'LOT_WF': lot_wf}
    for idx, key in enumerate(dx_coeff_keys):
        result_coeffs[key] = coeff_dx[idx]
    for idx, key in enumerate(dy_coeff_keys):
        result_coeffs[key] = coeff_dy[idx]
    wkrk_results.append(result_coeffs)
    
    # 예측값 및 잔차 계산
    pred_x = X_dx.dot(coeff_dx)
    pred_y = X_dy.dot(coeff_dy)
    residual_x = Y_dx - pred_x
    residual_y = Y_dy - pred_y
    
    # 원본 데이터에 결과 반영
    df_raw.loc[df_raw.index, 'pred_x'] = pred_x
    df_raw.loc[df_raw.index, 'pred_y'] = pred_y
    df_raw.loc[df_raw.index, 'residual_x'] = residual_x
    df_raw.loc[df_raw.index, 'residual_y'] = residual_y

    # 회귀 계수를 DataFrame으로 변환하여 반환
    df_coeff = pd.DataFrame(wkrk_results)
    return df_coeff

def psm_decorrect(df_raw, df_PSM):

    # 선택한 psm 옵션에 따른 디자인 행렬 함수 가져오기
    dm_func = cpe_k_to_fit
    
    # 그룹별로 계산 (그룹 기준: DieX, DieY)
    grouped = df_raw.groupby(['DieX', 'DieY'])
    psm_input_list = []

    # 필요한 RK 컬럼명 리스트 (안전한 추출을 위해 미리 정의)
    required_rk_cols = [f'RK{i}' for i in range(1, 73)]

    for (diex, diey), group in grouped:
        test = group['TEST']
        die_x = group['DieX']
        die_y = group['DieY']
        
        # [★수정] resi_to_cpe와 동일하게 좌표 정규화 필수!
        rx = group['coordinate_X'].values
        ry = group['coordinate_Y'].values

        X_dx, X_dy = dm_func(rx, ry)
        
        # dCol/dRow가 DieX/DieY와 매핑된다고 가정
        psm_row = df_PSM[
            (df_PSM['dCol'] == diex) &
            (df_PSM['dRow'] == diey)
        ]

        if psm_row.empty:
            Y_dx = np.zeros(X_dx.shape[1])
            Y_dy = np.zeros(X_dy.shape[1])
        else:
            # [수정] iloc 대신 컬럼명으로 안전하게 가져오기 (컬럼 부족 에러 방지)
            # df_PSM에 'RK1'~'RK72' 컬럼이 있다고 가정
            # 만약 df_PSM의 컬럼명이 다르다면(예: raw index) 확인 필요
            
            # 1. 먼저 RK 컬럼이 있는지 확인하고, 없으면 iloc으로 시도하되 범위 체크
            # 여기서는 안전하게 reindex 사용 (df_PSM이 이 코드의 결과물과 같다면 RK 이름이 있을 것임)
            try:
                rk_data = psm_row.reindex(columns=required_rk_cols, fill_value=0.0)
                rk_values = rk_data.values.flatten()
            except:
                # 만약 df_PSM이 외부 파일이라 컬럼명이 다르다면 기존 방식(iloc) 유지하되 예외처리
                # 4:76 은 총 72개 데이터를 의미
                raw_vals = psm_row.iloc[:, 4:76].values.flatten()
                if len(raw_vals) < 72:
                    rk_values = np.pad(raw_vals, (0, 72 - len(raw_vals)))
                else:
                    rk_values = raw_vals

            Y_dx = rk_values[::2]
            Y_dy = rk_values[1::2]

        psm_fit_x = X_dx.dot(Y_dx)
        psm_fit_y = X_dy.dot(Y_dy)

        residual_x_depsm = group['residual_x'].values - psm_fit_x
        residual_y_depsm = group['residual_y'].values - psm_fit_y

        psm_input_list.append(pd.DataFrame({
            'TEST' : test,
            'DieX' : die_x,
            'DieY' : die_y,
            'psm_fit_x': psm_fit_x,
            'psm_fit_y': psm_fit_y,
            'residual_x_depsm': residual_x_depsm,
            'residual_y_depsm': residual_y_depsm
        }))

    # 결과 병합
    df_psm_de = pd.concat(psm_input_list, ignore_index=True)

    # 정렬 및 정리
    df_psm_de = df_psm_de.sort_values(by=['TEST', 'DieX', 'DieY'])
    df_psm_de = df_psm_de.drop(['TEST', 'DieX', 'DieY'], axis=1)
    df_psm_de = df_psm_de.reset_index(drop=True)

    return df_psm_de

def get_weights_by_shape(num_cols):
    """(내부 함수) 컬럼 수에 따른 가중치 리스트 반환"""
    weights_21 = [0,0.01,0.01,1,1,0.1,1,1,1,0.1,1,1,1,1,1,1,1,1,1,1,1]
    weights_17 = [0,0.01,0.01,0.1,0.1,1,0.1,0.1,1,1,1,1,1,1,1,1,1]
    
    if num_cols == 21:
        return np.array(weights_21)
    elif num_cols == 17:
        return np.array(weights_17)
    else:
        # 정의되지 않은 경우 기본값 1.0 (균등 규제)
        return np.ones(num_cols)

def calculate_g_opt_relative(X_meas, X_full, alpha):

    # 1. 학습 데이터(X_meas)의 공분산 행렬 + 규제항 계산
    num_cols = X_meas.shape[1]
    weights = get_weights_by_shape(num_cols)
    L = np.diag(weights)
    
    XtX = X_meas.T @ X_meas
    inv_matrix = np.linalg.inv(XtX + alpha * L)

    term1 = X_full @ inv_matrix 
    H = term1 @ X_meas.T
    
    # 3. 분산 계산 (H * H.T 의 대각성분 = H의 각 행의 제곱합)
    # 굳이 H @ H.T 행렬 곱셈을 할 필요 없이 요소별 제곱 후 합산이 훨씬 빠름
    variances = np.sum(H**2, axis=1)
    return np.max(variances)

def solve_ridge_with_weights(X, Y, alpha):

    num_cols = X.shape[1]
    weights = get_weights_by_shape(num_cols)
    L = np.diag(weights)
    
    XtX = X.T @ X
    XtY = X.T @ Y
    
    regularized_matrix = XtX + (alpha * L)
    
    try:
        inv_matrix = np.linalg.inv(regularized_matrix)
        coeffs = inv_matrix @ XtY
    except np.linalg.LinAlgError:
        coeffs = np.zeros(num_cols)
        
    return coeffs

def resi_to_cpe(df_raw, cpe_option, lot_wf):
    # 선택한 옵션에 맞는 CPE 디자인 행렬 함수 가져오기
    dm_func = DESIGN_MATRIX_FUNCTIONS['cpe'][cpe_option]    
 
    grouped = df_raw.groupby(['DieX', 'DieY'])
    shot_regression_results = []

    # 가상격자 생성 루프
    for (die_x, die_y), group in grouped:

        if cpe_option == '38para':
            rx_ridge_raw, ry_ridge_raw = generate_virtual_grid(
                group['num_of_chip_X'].values[0], group['num_of_chip_Y'].values[0], 
                group['fcp_x'].values[0], group['fcp_y'].values[0], 
                group['STEP_PITCH_X'].values[0], group['STEP_PITCH_Y'].values[0],
                radius_limit=147000
            )
            # [방어코드] 가상 칩이 하나도 없으면 Skip
            if len(rx_ridge_raw) == 0:
                result = {'LOT_WF': lot_wf, 'DieX': die_x, 'DieY': die_y}
                for k in range(1, 66): result[f'RK{k}'] = 0.0
                shot_regression_results.append(result)
                continue

            # [★수정 핵심 1] 좌표 정규화 (Normalization)
            # 데이터를 150,000으로 나누어 -1 ~ 1 사이 값으로 만듦
            rx = group['coordinate_X'].values / NORM_FACTOR
            ry = group['coordinate_Y'].values / NORM_FACTOR
            
            # 가상 격자도 똑같이 정규화
            rx_ridge = rx_ridge_raw / NORM_FACTOR
            ry_ridge = ry_ridge_raw / NORM_FACTOR

            Yx = group['residual_x_depsm'].values
            Yy = group['residual_y_depsm'].values

            X_dx, X_dy = dm_func(rx, ry)
            Xf, Yf = dm_func(rx_ridge, ry_ridge)

            # --- X방향 최적화 (변수 분리) ---
            low_x, high_x = 0.0, 100.0
            best_alpha_x = high_x
            
            # alpha=0 체크
            if calculate_g_opt_relative(X_dx, Xf, 0.0) <= 1.0:
                best_alpha_x = 0.0
            else:
                mid_x = (low_x + high_x) / 2
                for _ in range(50): # 100번은 너무 많을 수 있음
                    g_val = calculate_g_opt_relative(X_dx, Xf, mid_x)
                    
                    if 0.999 <= g_val <= 1.0:
                        best_alpha_x = mid_x
                        high_x = mid_x # 더 작은 alpha 탐색
                        if (high_x - low_x) < 1e-4: break
                    elif g_val > 1.0: # 분산 큼 -> 규제 강화 (alpha 증가)
                        low_x = mid_x
                        mid_x = (low_x + high_x) / 2
                    else: # g_val < 0.999 -> 규제 과다 -> 규제 완화 (alpha 감소)
                        high_x = mid_x
                        mid_x = (low_x + high_x) / 2
            #print(die_x, die_y, 'x', best_alpha_x)
            coeff_dx_norm = solve_ridge_with_weights(X_dx, Yx, best_alpha_x)
            if coeff_dx_norm.ndim > 1: coeff_dx_norm = coeff_dx_norm.flatten()

            # --- Y방향 최적화 (변수 초기화 필수!) ---
            low_y, high_y = 0.0, 100.0
            best_alpha_y = high_y
            
            # Y방향 디자인행렬(X_dy)과 가상격자(Yf) 사용
            if calculate_g_opt_relative(X_dy, Yf, 0.0) <= 1.0:
                best_alpha_y = 0.0
            else:
                mid_y = (low_y + high_y) / 2
                for _ in range(50):
                    g_val = calculate_g_opt_relative(X_dy, Yf, mid_y)
                    
                    if 0.999 <= g_val <= 1.0:
                        best_alpha_y = mid_y
                        high_y = mid_y
                        if (high_y - low_y) < 1e-4: break
                    elif g_val > 1.0:
                        low_y = mid_y
                        mid_y = (low_y + high_y) / 2
                    else:
                        high_y = mid_y
                        mid_y = (low_y + high_y) / 2
            #print(die_x, die_y, 'y', best_alpha_y)
            coeff_dy_norm  = solve_ridge_with_weights(X_dy, Yy, best_alpha_y)
            if coeff_dy_norm.ndim > 1: coeff_dy_norm = coeff_dy_norm.flatten()

            cdx = coeff_dx_norm.copy()
            cdy = coeff_dy_norm.copy()

            # 결과 저장
            result = {
                'LOT_WF': lot_wf, 'DieX': die_x, 'DieY': die_y,
                'RK1': cdx[0], 'RK2': cdy[0],
                'RK3': cdx[1], 'RK4': cdy[1],
                'RK5': cdx[2], 'RK6': cdy[2],
                'RK7': cdx[3], 'RK8': cdy[3],
                'RK9': cdx[4], 'RK10': cdy[4],
                'RK11': cdx[5], 'RK12': cdy[5],
                'RK13': cdx[6], 'RK14': cdy[6],
                'RK15': cdx[7], 'RK16': cdy[7],
                'RK17': cdx[8], 'RK18': cdy[8],
                'RK19': cdx[9], 'RK20': 0, 'RK21': 0, 'RK22': cdy[9],
                'RK23': cdx[10], 'RK24': cdy[10],
                'RK25': cdx[11], 'RK26': cdy[11],
                'RK27': cdx[12], 'RK28': 0, 'RK29': cdx[13],
                'RK30': 0, 'RK31': 0, 'RK32': cdy[12],
                'RK33': 0, 'RK34': cdy[13], 'RK35': cdx[14],
                'RK36': cdy[14], 'RK37': cdx[15], 'RK38': 0,
                'RK39': cdx[16], 'RK40': 0, 'RK41': cdx[17],
                'RK42': 0, 'RK43': 0, 'RK44': 0, 'RK45': 0,
                'RK46': cdy[15], 'RK47': 0, 'RK48': cdy[16],
                'RK49': cdx[18], 'RK50': 0, 'RK51': cdx[19],
                'RK52': 0, 'RK53': 0, 'RK54': 0, 'RK55': 0,
                'RK56': 0, 'RK57': 0, 'RK58': 0, 'RK59': 0,
                'RK60': 0, 'RK61': 0, 'RK62': 0, 'RK63': 0, 'RK64': 0,
                'RK65': cdx[20]
            }

        else:
            # OLS (38para 아닐 때) - 여기도 정규화 하는게 좋음!
            # (일관성을 위해 여기도 NORM_FACTOR 나눔)
            rx = group['coordinate_X'].values / NORM_FACTOR
            ry = group['coordinate_Y'].values / NORM_FACTOR

            Yx = group['residual_x_depsm'].values
            Yy = group['residual_y_depsm'].values

            X_dx, X_dy = dm_func(rx, ry)
            
            cdx = np.linalg.lstsq(X_dx, Yx, rcond=None)[0]
            cdy = np.linalg.lstsq(X_dy, Yy, rcond=None)[0]            

            cdx[1:] /= NORM_FACTOR
            cdy[1:] /= NORM_FACTOR

            # ... (나머지 매핑 로직 동일) ...
            if cpe_option == '15para':
                # (생략: 기존 코드 복붙)
                # ...
                # result = { ... }
                pass # 위 코드 그대로 사용
            elif cpe_option == '6para':
                pass # 위 코드 그대로 사용
            else: # 18para
                pass # 위 코드 그대로 사용
             
            # (주의) 위 if-elif-else 블록 안의 내용은 질문자님 코드 그대로 넣으시면 됩니다.
            # 다만 result 변수가 만들어져야 함.
            # 여기서는 지면상 생략했으나 꼭 원래 로직 유지하세요.
            
            # 임시로 18para 예시만 넣어둠 (질문자님 코드 복사해서 쓰세요)
            if cpe_option == '15para':
                 result = { 'LOT_WF': lot_wf, 'DieX': die_x, 'DieY': die_y, 'RK1': cdx[0], 'RK2': cdy[0] } # ... 등등 채워넣기
            # ...

        shot_regression_results.append(result)

    df_cpe_k = pd.DataFrame(shot_regression_results)
    return df_cpe_k

def generate_virtual_grid(num_of_chip_X, num_of_chip_Y, 
                          fcp_x, fcp_y,  # 샷 중심 (Global 좌표)
                          step_pitch_x, step_pitch_y,
                          radius_limit=144000):
    
    # 1. 칩 사이즈 계산
    chip_pitch_x = step_pitch_x / num_of_chip_X
    chip_pitch_y = step_pitch_y / num_of_chip_Y
    
    # 2. Local 좌표계의 시작점 (샷의 왼쪽 아래)
    # 샷 중심이 (0,0)일 때의 왼쪽 아래 좌표 -> 음수 값이어야 정상!
    local_start_x = -(step_pitch_x / 2)
    local_start_y = -(step_pitch_y / 2)
    
    valid_local_points = set()
    
    # 3. 칩 순회
    for i in range(int(num_of_chip_X)):
        for j in range(int(num_of_chip_Y)):
            
            # (A) 현재 칩의 Local Boundary 계산
            # 이 값들은 음수와 양수를 오가야 합니다.
            c_min_lx = local_start_x + (i * chip_pitch_x)
            c_max_lx = c_min_lx + chip_pitch_x
            c_min_ly = local_start_y + (j * chip_pitch_y)
            c_max_ly = c_min_ly + chip_pitch_y
            
            # (B) 유효성 검사를 위한 Global Boundary 변환
            # Local 좌표 + fcp(샷 중심) = Global 좌표
            c_min_gx = c_min_lx + fcp_x
            c_max_gx = c_max_lx + fcp_x
            c_min_gy = c_min_ly + fcp_y
            c_max_gy = c_max_ly + fcp_y
            
            # (C) 네 귀퉁이 반경 체크 (Global 좌표 기준!)
            corners_global = [
                (c_min_gx, c_min_gy), (c_max_gx, c_min_gy),
                (c_min_gx, c_max_gy), (c_max_gx, c_max_gy)
            ]
            
            is_valid = True
            for gx, gy in corners_global:
                # 웨이퍼 중심(0,0)에서 144mm(144000um) 벗어나는지 확인
                if (gx**2 + gy**2) > radius_limit**2:
                    is_valid = False
                    break
            
            if not is_valid:
                continue

            # (D) 유효하다면 3x3 포인트 생성 (Local 좌표 기준 저장)
            # 우리는 최종적으로 Local 좌표가 필요하므로, 여기서 바로 Local로 만듭니다.
            l_xs = np.linspace(c_min_lx, c_max_lx, 3)
            l_ys = np.linspace(c_min_ly, c_max_ly, 3)
            
            for px in l_xs:
                for py in l_ys:
                    # 소수점 오차 제거 후 저장
                    valid_local_points.add((round(px, 3), round(py, 3)))
    
    # 4. 정렬 및 반환
    # 좌표를 보기 좋게 정렬 (Y우선 -> X우선)
    sorted_points = sorted(list(valid_local_points), key=lambda p: (p[1], p[0]))
    
    if not sorted_points:
        return np.array([]), np.array([])
        
    rx_list, ry_list = zip(*sorted_points)
    
    return np.array(rx_list), np.array(ry_list)

def psm_correct(df_raw, df_cpe_k):
    dm_func = cpe_k_to_fit 
    grouped = df_raw.groupby(['DieX', 'DieY'])
    psm_input_list = []

    required_rk_cols = [f'RK{i}' for i in range(1, 73)] 

    for (diex, diey), group in grouped:
        test = group['TEST']
        die_x = group['DieX']
        die_y = group['DieY']
        
        # ★★★ 여기서도 똑같이 나누어줍니다! ★★★
        rx = group['coordinate_X'].values / NORM_FACTOR
        ry = group['coordinate_Y'].values / NORM_FACTOR

        X_dx, X_dy = dm_func(rx, ry)
        
        psm_row = df_cpe_k[
            (df_cpe_k['DieX'] == diex) &
            (df_cpe_k['DieY'] == diey)
        ]

        if psm_row.empty:
            Y_dx = np.zeros(X_dx.shape[1])
            Y_dy = np.zeros(X_dy.shape[1])
        else:
            rk_data = psm_row.reindex(columns=required_rk_cols, fill_value=0.0)
            rk_values = rk_data.values.flatten()
            Y_dx = rk_values[::2]
            Y_dy = rk_values[1::2]
            Y_dx[1:] *= NORM_FACTOR
            Y_dy[1:] *= NORM_FACTOR

        psm_fit_x = X_dx.dot(Y_dx)
        psm_fit_y = X_dy.dot(Y_dy)

        residual_x_psmco = group['residual_x_depsm'].values - psm_fit_x
        residual_y_psmco = group['residual_y_depsm'].values - psm_fit_y

        psm_input_list.append(pd.DataFrame({
            'TEST' : test,
            'DieX' : die_x,
            'DieY' : die_y,
            'psm_fit_x': psm_fit_x,
            'psm_fit_y': psm_fit_y,
            'residual_x_psmco': residual_x_psmco,
            'residual_y_psmco': residual_y_psmco
        }))

    df_psm_de = pd.concat(psm_input_list, ignore_index=True)
    df_psm_de = df_psm_de.sort_values(by=['TEST', 'DieX', 'DieY'])
    df_psm_de = df_psm_de.drop(['TEST', 'DieX', 'DieY'], axis=1)
    df_psm_de = df_psm_de.reset_index(drop=True)

    return df_psm_de
